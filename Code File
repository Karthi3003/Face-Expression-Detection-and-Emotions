### Code: Face Expression Detection and Emotion Recognition

**1. Install necessary libraries:**

```bash
pip install opencv-python opencv-python-headless tensorflow keras numpy dlib
```

**2. Python code for face detection and emotion recognition:**

```python
# Import necessary libraries
import cv2
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array

# Load pre-trained face detector (Haar Cascade) and the emotion recognition model (CNN)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
emotion_model = load_model('emotion_model.h5')  # Make sure you have the pre-trained model

# Emotion labels
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

# Initialize video capture for real-time emotion recognition
cap = cv2.VideoCapture(0)  # Webcam

while True:
    # Read frame from video capture
    ret, frame = cap.read()
    if not ret:
        break
    
    # Convert the frame to grayscale for face detection
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Detect faces in the frame
    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))
    
    # Loop over the detected faces
    for (x, y, w, h) in faces:
        # Draw a rectangle around the face
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        
        # Extract the face region of interest (ROI) and preprocess it
        face_roi = gray_frame[y:y + h, x:x + w]
        face_roi = cv2.resize(face_roi, (48, 48))
        face_roi = face_roi.astype('float') / 255.0
        face_roi = img_to_array(face_roi)
        face_roi = np.expand_dims(face_roi, axis=0)
        
        # Predict the emotion using the trained model
        emotion_prediction = emotion_model.predict(face_roi)
        max_index = np.argmax(emotion_prediction[0])
        emotion_label = emotion_labels[max_index]
        
        # Put the emotion label text on the screen
        cv2.putText(frame, emotion_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
    
    # Display the resulting frame with the detected face and emotion label
    cv2.imshow('Emotion Detector', frame)
    
    # Press 'q' to exit the video capture
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the windows
cap.release()
cv2.destroyAllWindows()
```

### Content for GitHub Readme:

---

# Face Expression Detection and Emotion Recognition

This project is a Python-based system that detects human faces in real-time and classifies their emotions using deep learning. The system utilizes OpenCV for face detection and a pre-trained Convolutional Neural Network (CNN) model to classify emotions.

## Features

- Real-time face detection using OpenCV's Haar Cascade classifier.
- Emotion recognition using a pre-trained CNN model based on the FER2013 dataset.
- Classifies emotions into the following categories:
  - Happy
  - Sad
  - Angry
  - Neutral
  - Surprise
  - Fear
  - Disgust
- Live video stream detection from the webcam.

## Tech Stack

- **Language**: Python
- **Libraries**: OpenCV, TensorFlow, Keras, Numpy
- **Model**: Pre-trained CNN on the FER2013 dataset
- **Platform**: Local Machine

## Prerequisites

- Python 3.x
- OpenCV for Python
- TensorFlow and Keras for deep learning
- Pre-trained emotion recognition model (`emotion_model.h5`)

### Installing Dependencies

```bash
pip install opencv-python opencv-python-headless tensorflow keras numpy dlib
```

### Running the Project

1. Clone the repository.

   ```bash
   git clone https://github.com/[your-username]/face-expression-detection.git
   ```

2. Download the pre-trained emotion recognition model and place it in the project directory. You can use a model like [FER2013](https://www.kaggle.com/datasets/msambare/fer2013) and convert it to an H5 file using Keras.

3. Run the Python script.

   ```bash
   python face_emotion_detection.py
   ```

4. The webcam will open, and the system will start detecting faces and predicting emotions in real-time.

### Project Overview

The **Face Expression Detection and Emotion Recognition** system was designed to identify human emotions in real-time by analyzing facial expressions. This project has various applications, including:

- Human-computer interaction
- Mental health analysis
- Real-time emotion tracking in surveillance systems

#### Face Detection:
The system uses OpenCV's Haar Cascade classifier to detect faces in the video stream.

#### Emotion Recognition:
We used a deep learning-based Convolutional Neural Network (CNN) trained on the FER2013 dataset. The model processes the detected face and classifies it into one of the seven emotions.

### Emotion Detection Example

When the system detects a face, it draws a bounding box around it and displays the predicted emotion. The real-time performance is optimized to ensure smooth operation during live video capture.

![Emotion Detection](images/emotion_example.png)

### Future Work

- Improve the CNN model by using a larger dataset and experimenting with deeper architectures.
- Add support for recognizing multiple faces and emotions simultaneously.
- Optimize the system for better real-time performance.



---

